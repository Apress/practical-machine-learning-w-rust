{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from numpy import genfromtxt\n",
    "from sklearn.datasets import load_boston\n",
    "from tensorflow.python.saved_model.builder import SavedModelBuilder\n",
    "from tensorflow.python.saved_model.signature_def_utils import build_signature_def\n",
    "from tensorflow.python.saved_model.signature_constants import REGRESS_METHOD_NAME\n",
    "from tensorflow.python.saved_model.tag_constants import TRAINING, SERVING\n",
    "from tensorflow.python.saved_model.utils import build_tensor_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_dataset(filePath,delimiter=','):\n",
    "#     return genfromtxt(filePath, delimiter=delimiter)\n",
    "\n",
    "# def read_boston_data():\n",
    "#     boston = load_boston()\n",
    "#     features = np.array(boston.data)\n",
    "#     labels = np.array(boston.target)\n",
    "#     return features, labels\n",
    "\n",
    "# def feature_normalize(dataset):\n",
    "#     mu = np.mean(dataset,axis=0)\n",
    "#     sigma = np.std(dataset,axis=0)\n",
    "#     return (dataset - mu)/sigma\n",
    "\n",
    "# def append_bias_reshape(features,labels):\n",
    "#     n_training_samples = features.shape[0]\n",
    "#     n_dim = features.shape[1]\n",
    "#     f = np.reshape(np.c_[np.ones(n_training_samples),features],[n_training_samples,n_dim + 1])\n",
    "#     l = np.reshape(labels,[n_training_samples,1])\n",
    "#     return f, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features,labels = read_boston_data()\n",
    "# normalized_features = feature_normalize(features)\n",
    "# f, l = append_bias_reshape(normalized_features,labels)\n",
    "# f = features\n",
    "# n_dim = f.shape[1]\n",
    "\n",
    "# rnd_indices = np.random.rand(len(f)) < 0.80\n",
    "\n",
    "# train_x = f[rnd_indices]\n",
    "# train_y = l[rnd_indices]\n",
    "# test_x = f[~rnd_indices]\n",
    "# test_y = l[~rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "# training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "\n",
    "X = tf.placeholder(tf.float64,[None,n_dim], name=\"x\")\n",
    "X_test = tf.placeholder(tf.float64,[None,n_dim], name=\"x_test\")\n",
    "Y = tf.placeholder(tf.float64,[None,1], name=\"y\")\n",
    "W = tf.Variable(tf.ones([n_dim,1],dtype=tf.float64), name=\"w\")\n",
    "\n",
    "init = tf.variables_initializer(tf.global_variables(), name=\"init\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.matmul(X, W, name=\"y_hat\")\n",
    "y_preds = tf.matmul(X_test, W, name=\"y_preds\")\n",
    "cost = tf.reduce_mean(tf.square(y_ - Y))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost, name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "\n",
    "# for epoch in range(training_epochs):\n",
    "#     sess.run(training_step,feed_dict={X:train_x,Y:train_y})\n",
    "#     cost_history = np.append(cost_history,sess.run(cost,feed_dict={X: train_x,Y: train_y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(range(len(cost_history)),cost_history)\n",
    "# plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_y = sess.run(y_, feed_dict={X: test_x})\n",
    "# mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "# print(\"MSE: %.4f\" % sess.run(mse)) \n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(test_y, pred_y)\n",
    "# ax.plot([test_y.min(), test_y.max()], [test_y.min(), test_y.max()], 'k--', lw=3)\n",
    "# ax.set_xlabel('Measured')\n",
    "# ax.set_ylabel('Predicted')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://aqibsaeed.github.io/2016-07-07-TensorflowLR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition = tf.Session().graph_def\n",
    "directory = 'boston_regression'\n",
    "builder = SavedModelBuilder(directory)\n",
    "# tf.train.write_graph(definition, directory, 'saved_model.pbtxt', as_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: boston_regression/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=tf.get_default_graph()) as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    signature_inputs = {\n",
    "        \"x\": build_tensor_info(X),\n",
    "        \"x_test\": build_tensor_info(X_test),\n",
    "        \"y\": build_tensor_info(Y)\n",
    "    }\n",
    "    signature_outputs = {\n",
    "        \"out\": build_tensor_info(y_preds)\n",
    "    }\n",
    "    signature_def = build_signature_def(\n",
    "        signature_inputs, signature_outputs,\n",
    "        REGRESS_METHOD_NAME)\n",
    "    builder.add_meta_graph_and_variables(\n",
    "        sess, [TRAINING, SERVING],\n",
    "        signature_def_map={\n",
    "            REGRESS_METHOD_NAME: signature_def\n",
    "        },\n",
    "        assets_collection=tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS))\n",
    "    builder.save(as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
